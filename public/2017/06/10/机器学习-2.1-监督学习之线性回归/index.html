<!DOCTYPE html>
<html >
<head>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="zhengchenyu" />



<meta name="description" content="监督学习  如上图所示，监督学习实质就是: 在给定训练集合，使用某种学习算法得到学习函数h，能够较为准确的预测y。 1 线性回归下面有一组房价关于房子面积以及卧室数目的样本数据。试着从这些样本数据中构造线性模型，以预测房价。    房间数目 房间大小 房价     2 88.0 1760288   2 88.0 1762136   … … …    1.1 梯度下降法1.1.1 梯度下降法说明">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习 2.1 监督学习之线性回归">
<meta property="og:url" content="http://yoursite.com/2017/06/10/机器学习-2.1-监督学习之线性回归/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="监督学习  如上图所示，监督学习实质就是: 在给定训练集合，使用某种学习算法得到学习函数h，能够较为准确的预测y。 1 线性回归下面有一组房价关于房子面积以及卧室数目的样本数据。试着从这些样本数据中构造线性模型，以预测房价。    房间数目 房间大小 房价     2 88.0 1760288   2 88.0 1762136   … … …    1.1 梯度下降法1.1.1 梯度下降法说明">
<meta property="og:image" content="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E8%AF%B4%E6%98%8E.png">
<meta property="og:image" content="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%88%BF%E4%BB%B7%E7%82%B9%E5%9B%BE.png">
<meta property="og:image" content="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%88%BF%E4%BB%B7%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BB%93%E6%9E%9C1.png">
<meta property="og:image" content="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%88%BF%E4%BB%B7%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BB%93%E6%9E%9C2.png">
<meta property="og:image" content="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%B1%80%E9%83%A8%E5%8A%A0%E6%9D%83%E5%88%86%E6%9E%90%E7%BB%93%E6%9E%9C%E5%9B%BE.png">
<meta property="og:updated_time" content="2017-08-08T09:57:49.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习 2.1 监督学习之线性回归">
<meta name="twitter:description" content="监督学习  如上图所示，监督学习实质就是: 在给定训练集合，使用某种学习算法得到学习函数h，能够较为准确的预测y。 1 线性回归下面有一组房价关于房子面积以及卧室数目的样本数据。试着从这些样本数据中构造线性模型，以预测房价。    房间数目 房间大小 房价     2 88.0 1760288   2 88.0 1762136   … … …    1.1 梯度下降法1.1.1 梯度下降法说明">
<meta name="twitter:image" content="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E8%AF%B4%E6%98%8E.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>机器学习 2.1 监督学习之线性回归 | Hexo</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: undefined
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->






</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">zhengchenyu</a></h1>
        </hgroup>

        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:123@123.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注于前端</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">zhengchenyu</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">zhengchenyu</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:123@123.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-机器学习-2.1-监督学习之线性回归" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/06/10/机器学习-2.1-监督学习之线性回归/" class="article-date">
      <time datetime="2017-06-10T13:52:17.000Z" itemprop="datePublished">2017-06-10</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习 2.1 监督学习之线性回归
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <script type="text/javascript" src="/Users/zcy/Desktop/study/git/MathJax-master/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h1 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h1><p><img src="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E8%AF%B4%E6%98%8E.png" alt="监督学习说明"> </p>
<p>如上图所示，监督学习实质就是: 在给定训练集合，使用某种学习算法得到学习函数h，能够较为准确的预测y。</p>
<h2 id="1-线性回归"><a href="#1-线性回归" class="headerlink" title="1 线性回归"></a>1 线性回归</h2><p>下面有一组房价关于房子面积以及卧室数目的样本数据。试着从这些样本数据中构造线性模型，以预测房价。</p>
<table>
<thead>
<tr>
<th>房间数目</th>
<th>房间大小</th>
<th>房价</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>88.0</td>
<td>1760288</td>
</tr>
<tr>
<td>2</td>
<td>88.0</td>
<td>1762136</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<h3 id="1-1-梯度下降法"><a href="#1-1-梯度下降法" class="headerlink" title="1.1 梯度下降法"></a>1.1 梯度下降法</h3><h4 id="1-1-1-梯度下降法说明"><a href="#1-1-1-梯度下降法说明" class="headerlink" title="1.1.1 梯度下降法说明"></a>1.1.1 梯度下降法说明</h4><p>假设房价与房间数目、房屋带下呈线性关系，有如下关系:</p>

$${h_\theta }(x) = {\theta _0} + {\theta _1}{x _1} + {\theta _2}{x _2}$$

<p>假设\({x_0} = 1\),则有如下公式:</p>

$${h_\theta }(x) = {\theta _0}{x _0} + {\theta _1}{x _1} + {\theta _2}{x _2} = \sum\limits _{i = 0}^n{\theta _i}{x _i}$$

<p>假设y为样本实际的值，因此有如下损失函数可以定义：</p>

$$J(\theta ) = \frac{1}{2}\sum\limits _{i = 0}^m {{{({h _\theta }({x^i}) - {y^i})}^2}} $$

<p>我们只要保证上面的公式趋于0就是合适的，因此这个问题就转化为得到合适的使得\(J(\theta )\)最小。实际也就转化为利用最小二乘法进行回归分析。</p>
<p>做这样一个想想，对于二维的情况。\(J(\theta )\)是一个关于的二维函数的话，他一定类似于锅状的凸函数。根据梯度下降算法(参考&lt;&lt;最优化方法&gt;&gt;)，沿着某一个方向的负梯度方向就是在该方向上下降最大的方向。因此，我们可以选取各个维度的负梯度作为下降的方向，为了方便各个梯度方向选取同样的步长。因此，我们对任意维度采用如下公式进行递归(为步长)：</p>

$${\theta _j}: = {\theta _j} - \alpha \frac{{\partial J(\theta )}}{{\partial {\theta _j}}} = {\theta _j} - \alpha \sum\limits _{i = 0}^m{({h _\theta }({x^i}) - {y^i}) {x _j}}$$

<p>我们简化，我们仅仅对房间大小与房价的一维关系进行回归分析。</p>
<blockquote>
<p>注：对于每一次迭代运算都需要对所有全量信息进行计算。这样带来了大量的计算。工程上可以采用采样的方式计算新的，这里数据较少，就不用该方法了。</p>
</blockquote>
<h4 id="1-1-2-梯度下降法案例"><a href="#1-1-2-梯度下降法案例" class="headerlink" title="1.1.2 梯度下降法案例"></a>1.1.2 梯度下降法案例</h4><p>我们有一组数据，为房间大小与房价的关系。我们的目标是通过使用梯度下降算法，模拟得到满足学习函数，以预测房价。可以看如下点图:</p>
<p><img src="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%88%BF%E4%BB%B7%E7%82%B9%E5%9B%BE.png" alt="房价点图"></p>
<p>根据上一节的公式编写如下代码进行回归分析:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">% 以下为主算法流程</div><div class="line">% y = xita0 +xita1*x</div><div class="line">mfilename=&apos;/Users/zcy/Desktop/mlearning/prices&apos;</div><div class="line">[v,x,y]=textread(mfilename,&apos;%n%n%n&apos;);</div><div class="line"> </div><div class="line">limit = 1000;</div><div class="line">y=y./10000;</div><div class="line">% step</div><div class="line">a = 0.0000001;</div><div class="line"> </div><div class="line">xita0 = 0.01;</div><div class="line">xita1 = 1.6;</div><div class="line">err = JFun(x,y,xita0,xita1);</div><div class="line">disp([&apos;err = &apos;,num2str(err)])</div><div class="line">count = 0; </div><div class="line">while err&gt;limit </div><div class="line">    xita0 = xita0 - a*gradient(x,y,xita0,xita1,true);</div><div class="line">    xita1 = xita1 - a*gradient(x,y,xita0,xita1,false)    </div><div class="line">    err = JFun(x,y,xita0,xita1);</div><div class="line">    count = count + 1;</div><div class="line">    disp([&apos;err = &apos;,num2str(err),&apos;, count = &apos;,num2str(count)])</div><div class="line">end</div><div class="line"> </div><div class="line">scatter(x,y,&apos;k&apos;)</div><div class="line">hold on</div><div class="line">x1 = 70:0.01:100;</div><div class="line">y1 = xita0+x1.*xita1;</div><div class="line">plot(x1,y1)</div></pre></td></tr></table></figure>
<p>JFun.m文件流程:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">function [s]  = JFun(x,y,xita0,xita1)</div><div class="line">s = 0;</div><div class="line">for i = 1:size(x)</div><div class="line">   s = s + 0.5*((xita0*1+xita1*x(i)-y(i))^2);</div><div class="line">end</div></pre></td></tr></table></figure>
<p>gradient.m文件: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">function [s]  = gradient(x,y,xita0,xita1,b)</div><div class="line">s = 0;</div><div class="line">if b </div><div class="line">    for i = 1:size(x)</div><div class="line">        s = s + (xita0*1+xita1*x(i)-y(i))*1;</div><div class="line">    end</div><div class="line">else </div><div class="line">    for i = 1:size(x)</div><div class="line">        s = s + (xita0*1+xita1*x(i)-y(i))*x(i);</div><div class="line">    end</div><div class="line">end</div></pre></td></tr></table></figure>
<blockquote>
<p>这里为了示意，代码仅考虑两维，实际不建议代码这样写。另外，选取合适的limit值和步长需要经过打印调试。选取不当，容易造成函数无法收敛。</p>
</blockquote>
<p>回归得到如下曲线：</p>
<p><img src="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%88%BF%E4%BB%B7%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BB%93%E6%9E%9C1.png" alt="回归曲线1"></p>
<p>修改limit为500之后，回归更加准确。</p>
<p><img src="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%88%BF%E4%BB%B7%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%BB%93%E6%9E%9C2.png" alt="回归曲线2"></p>
<h3 id="1-2-线性回归的解析解"><a href="#1-2-线性回归的解析解" class="headerlink" title="1.2 线性回归的解析解"></a>1.2 线性回归的解析解</h3><p>略，详见斯坦福大学机器学习讲义。</p>
<h3 id="1-3-线性回归的概率解释"><a href="#1-3-线性回归的概率解释" class="headerlink" title="1.3 线性回归的概率解释"></a>1.3 线性回归的概率解释</h3><p>本节从概率的角度进行线性回归分析。对我们的任意一组变量有如下公式：</p>

$${y^i} = {\theta ^T}{x^i} + {\varepsilon ^i}$$

<p>其中\(\varepsilon \)为误差，假设我们的误差服从正太分布<br>\({\varepsilon ^i} \sim {\rm N}(0,{\sigma ^2})\)。即有如下公式：</p>

$$p({\varepsilon ^i}) = \frac{1}{{\sqrt {2\pi } \sigma }}{e^{( - \frac{{{{({\varepsilon ^i})}^2}}}{{2{\sigma ^2}}})}}$$

<p>代入上面的公式有：</p>

$$p({y^i}|{x^i},\theta ) = \frac{1}{{\sqrt {2\pi } \sigma }}{e^{( - \frac{{{{({y^i} - {\theta ^T}{x^i})}^2}}}{{2{\sigma ^2}}})}}$$

<p>该公式的含义为在已知\(x ^i \)和\(\theta \)的情况下，得到准确的\(y ^i \)概率。我们可以利用最大似然估计，最大释然估计实质就是对所有采样值调整参数得到最准确y值的方法。(详细请看概率论)。有如下公式:</p>

$$L(\theta ) = \prod\limits _{i = 1}^m {p({y^i}|{x^i},\theta )}  = \prod\limits _{i = 1}^m {\frac{1}{{\sqrt {2\pi } \sigma }}{e^{( - \frac{{{{({y^i} - {\theta ^T}{x^i})}^2}}}{{2{\sigma ^2}}})}}} $$

<p>上面的公式是对各个数据采样得到准确y的概率的乘积，问题也就转化为调整使的上式最大，进一步转化为求的上式的倒数为0的情况。对上式去log，如下:</p>

$$[\log (L(\theta )) = \log (\prod\limits _{i = 1}^m {\frac{1}{{\sqrt {2\pi } \sigma }}{e^{( - \frac{{{{({y^i} - {\theta ^T}{x^i})}^2}}}{{2{\sigma ^2}}})}}} )$$


$$\log (L(\theta )) = \sum\limits _{i = 1}^m {\log \frac{1}{{\sqrt {2\pi } \sigma }}{e^{( - \frac{{{{({y^i} - {\theta ^T}{x^i})}^2}}}{{2{\sigma ^2}}})}}}  = m\log \frac{1}{{\sqrt {2\pi } \sigma }} - \frac{1}{{{\sigma ^2}}} \cdot \frac{1}{2}\sum\limits _{i = 1}^m {{{({y^i} - {\theta ^T}{x^i})}^2}} $$

<p>看上式最后一项，前面部分为常数，因此问题有转化为求最小值的问题了。</p>
<p><strong>因此从概率角度上考虑误差的情况下，我们前面基于最小二乘的算法也是正确的。</strong></p>
<h3 id="1-4-局部加权回归-Loess"><a href="#1-4-局部加权回归-Loess" class="headerlink" title="1.4 局部加权回归(Loess)"></a>1.4 局部加权回归(Loess)</h3><h4 id="1-4-1-局部加权回归说明"><a href="#1-4-1-局部加权回归说明" class="headerlink" title="1.4.1 局部加权回归说明"></a>1.4.1 局部加权回归说明</h4><p>有一组非线性去先，譬如\(y = {x^2}\)。如果使用之前的方法拟合(即假设其为y=kx+b型曲线)，必然不会得到理想的结果。对于这样的问题，我们想求出\(f(20)\),加入我们只对\(x\)在20附近的样本进行一维拟合，我们就可以得到一个精确值。因此，我们引入如下公式：</p>

$$J(\theta ) = \frac{1}{2}\sum\limits_ {i = 0}^m {{\omega ^i}{{({h_ \theta }({x^i}) - {y^i})}^2}} $$


$${\omega ^i} = {e^{ - \frac{{{{({x^i} - x)}^2}}}{{2{\tau ^2}}}}}$$

<p>其中，在原来的价值函数中引入权重\(\omega\)。\(\tau\)是波长，该值越小，越趋于向20附近的值进行回归计算。对于求\(f(20)\)的情况，在的公式中\(x\)恒为20,可以知道该值在\(x ^i\)趋近于20的时候趋近于1，趋近于\( \pm \infty \)的时候趋近于0。也就是相当于仅仅是在20附近进行拟合。由于新引入的权重函数与\(\theta\)无关。所以得到如下公式:</p>

$${\theta _j}: = {\theta _j} - \alpha \frac{{\partial J(\theta )}}{{\partial {\theta _j}}} = {\theta _j} - \alpha \sum\limits _{i = 0}^m {{\omega ^i}({h _\theta }({x^i}) - {y^i})} {x _j}$$

<p>我们这里是一个一维的问题，可以得到如下公式:</p>

$$J(\theta ) = \frac{1}{2}\sum\limits _{i = 0}^m {{\omega ^i}{{({\theta _1}{x^i} + {\theta _0} - {y^i})}^2}} $$


$${\omega ^i} = {e^{ - \frac{{{{({x^i} - 20)}^2}}}{{2{\tau ^2}}}}}$$

<h4 id="1-4-2-局部加权回归案例"><a href="#1-4-2-局部加权回归案例" class="headerlink" title="1.4.2 局部加权回归案例"></a>1.4.2 局部加权回归案例</h4><p>主流程代码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">% y = xita0 +xita1*x</div><div class="line">x = -100:1:100;</div><div class="line">y = x.*x;</div><div class="line">% x= 20, y = 40x - 400</div><div class="line">x0 = 20;       </div><div class="line">tao = 5;</div><div class="line">a = 0.0003;</div><div class="line"> </div><div class="line">xita0 = -1;</div><div class="line">xita1 = 1;</div><div class="line">limit = 7850;</div><div class="line">err = JFun_Loess(x,y,xita0,xita1,x0,tao);</div><div class="line">count = 0; </div><div class="line">while err&gt;limit </div><div class="line">    xita0 = xita0 - a*gradient_Loess(x,y,xita0,xita1,true,x0,tao);</div><div class="line">    xita1 = xita1 - a*gradient_Loess(x,y,xita0,xita1,false,x0,tao);    </div><div class="line">    err = JFun_Loess(x,y,xita0,xita1,x0,tao);</div><div class="line">    count = count + 1;</div><div class="line">end</div><div class="line"> </div><div class="line">scatter(x,y,&apos;k&apos;)</div><div class="line">hold on</div><div class="line">x1 = -100:1:100;</div><div class="line">y1 = xita0+x1.*xita1;</div><div class="line">disp([&apos;xita0 = &apos;,num2str(xita0),&apos;, xita1 = &apos;,num2str(xita1)])</div><div class="line">plot(x1,y1)</div></pre></td></tr></table></figure>
<p>JFun_loess:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">function [s]  = JFun_Loess(x,y,xita0,xita1,x0,tao)</div><div class="line">s = 0;</div><div class="line">for i = 1:size(x&apos;)</div><div class="line">    s = s + 0.5*((xita0*1+xita1*x(i)-y(i))^2)*exp(-0.5*(x(i)-x0)*(x(i)-x0)/tao/tao);</div><div class="line">end</div></pre></td></tr></table></figure>
<p>gradient_Loess:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">function [s]  = gradient_Loess(x,y,xita0,xita1,b,x0,tao)</div><div class="line">s = 0;</div><div class="line">if b </div><div class="line">    for i = 1:size(x&apos;)</div><div class="line">        s = s + (xita0*1+xita1*x(i)-y(i))*1*exp(-0.5*(x(i)-x0)*(x(i)-x0)/tao/tao);</div><div class="line">    end</div><div class="line">else</div><div class="line">    for i = 1:size(x&apos;)</div><div class="line">        s = s + (xita0*1+xita1*x(i)-y(i))*x(i)*exp(-0.5*(x(i)-x0)*(x(i)-x0)/tao/tao);</div><div class="line">    end</div><div class="line">end</div></pre></td></tr></table></figure>
<p>在x=20处分析，理论值为y = 40x – 400。经过模拟得到的值为y=39.6825x-368.253。<br>下图为得到的结果，实际上已经非常接近这个二次曲线在20这个位置的切线了。</p>
<p><img src="http://ord3iii9m.bkt.clouddn.com/image/github/mlearning%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E5%B1%80%E9%83%A8%E5%8A%A0%E6%9D%83%E5%88%86%E6%9E%90%E7%BB%93%E6%9E%9C%E5%9B%BE.png" alt="局部加权分析结果图"></p>
<h2 id="2-回归分析相关概念"><a href="#2-回归分析相关概念" class="headerlink" title="2 回归分析相关概念"></a>2 回归分析相关概念</h2><p>另外引申一个概念:</p>
<p>之前我们把房价与房屋大小认为是一个一维曲线。如上图，可以看出很多点被反映到曲线中。我们可以称其为欠拟合过程。与之对应的，如果使用高阶函数进行拟合，即假如样本有5个点，我们可以通过一个4阶函数的曲线进行完整拟合，但是这样的曲线往往并不是一个良好的房价与房屋大小的反映，这被称为过拟合。(该部分内容可以想见矩阵与数值分析)</p>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2017/06/10/机器学习-2.1-监督学习之线性回归/">机器学习 2.1 监督学习之线性回归</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">zhengchenyu</a></p>
        <p><span>发布时间:</span>2017-06-10, 21:52:17</p>
        <p><span>最后更新:</span>2017-08-08, 17:57:49</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2017/06/10/机器学习-2.1-监督学习之线性回归/" title="机器学习 2.1 监督学习之线性回归">http://yoursite.com/2017/06/10/机器学习-2.1-监督学习之线性回归/</a>
            <span class="copy-path" data-clipboard-text="原文: http://yoursite.com/2017/06/10/机器学习-2.1-监督学习之线性回归/　　作者: zhengchenyu" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2017/06/13/机器学习-2.2-监督学习之分类/">
                    机器学习 2.2 监督学习之逻辑回归
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2017/06/10/机器学习-1-绪论/">
                    机器学习 1 绪论
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#监督学习"><span class="toc-number">1.</span> <span class="toc-text">监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-线性回归"><span class="toc-number">1.1.</span> <span class="toc-text">1 线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-梯度下降法"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 梯度下降法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-1-梯度下降法说明"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">1.1.1 梯度下降法说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-2-梯度下降法案例"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">1.1.2 梯度下降法案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-线性回归的解析解"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 线性回归的解析解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-线性回归的概率解释"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 线性回归的概率解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-局部加权回归-Loess"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4 局部加权回归(Loess)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-1-局部加权回归说明"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">1.4.1 局部加权回归说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-2-局部加权回归案例"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">1.4.2 局部加权回归案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-回归分析相关概念"><span class="toc-number">1.2.</span> <span class="toc-text">2 回归分析相关概念</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"机器学习 2.1 监督学习之线性回归　| Hexo　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2017/06/13/机器学习-2.2-监督学习之分类/" title="上一篇: 机器学习 2.2 监督学习之逻辑回归">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2017/06/10/机器学习-1-绪论/" title="下一篇: 机器学习 1 绪论">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/10/22/机器学习-3-2-非监督学习之主成分分析/">机器学习-3.2-非监督学习之主成分分析.md</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/15/机器学习-2-8-监督学习之k近邻算法/">机器学习-2.8-监督学习之k近邻算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/24/机器学习-3-1-非监督学习之聚类/">机器学习-3.1-非监督学习之聚类.md</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/08/机器学习-2-7-监督学习之支持向量机/">机器学习-2.7-监督学习之支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/05/机器学习-2-6-监督学习之朴素贝叶斯算法/">机器学习-2.6-监督学习之朴素贝叶斯算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/">机器学习-2.5-监督学习之生成型学习算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/24/机器学习-2-4-监督学习之softmax/">机器学习-2.4-监督学习之softmax</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/16/机器学习-2.3-监督学习之通用线性模型/">机器学习-2.3-监督学习之通用线性模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/13/机器学习-2.2-监督学习之分类/">机器学习 2.2 监督学习之逻辑回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/10/机器学习-2.1-监督学习之线性回归/">机器学习 2.1 监督学习之线性回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/10/机器学习-1-绪论/">机器学习 1 绪论</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/06/MyFirstBlog/">MyFirstBlog</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016-2017 zhengchenyu
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>