<!DOCTYPE html>
<html >
<head>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="zhengchenyu" />



<meta name="description" content="生成型学习算法1 生成型学习算法简述我们之前讲到的算法。譬如逻辑回归，试图从\(x\)直接学习得到一组映射关系到\(y\)，即通过样本\((x,y)\)学习得到,使得其能够准确的预测\(y\)。这类算法叫做判别性学习算法。 本节我们将介绍生成学习型算法。举个例子，对于一个大象，我们可以为大象构造一个关于其特征的模型。对于一条狗，同样可以为狗构造一个关于关于其特征的模型。对于一个新动物，我们可以">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-2.5-监督学习之生成型学习算法">
<meta property="og:url" content="http://yoursite.com/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="生成型学习算法1 生成型学习算法简述我们之前讲到的算法。譬如逻辑回归，试图从\(x\)直接学习得到一组映射关系到\(y\)，即通过样本\((x,y)\)学习得到,使得其能够准确的预测\(y\)。这类算法叫做判别性学习算法。 本节我们将介绍生成学习型算法。举个例子，对于一个大象，我们可以为大象构造一个关于其特征的模型。对于一条狗，同样可以为狗构造一个关于关于其特征的模型。对于一个新动物，我们可以">
<meta property="og:image" content="http://yoursite.com/images/机器学习/监督学习-生成型算法GDA样本.png">
<meta property="og:image" content="http://yoursite.com/images/机器学习/监督学习-生成型算法GDA结果.png">
<meta property="og:updated_time" content="2017-08-05T12:51:24.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习-2.5-监督学习之生成型学习算法">
<meta name="twitter:description" content="生成型学习算法1 生成型学习算法简述我们之前讲到的算法。譬如逻辑回归，试图从\(x\)直接学习得到一组映射关系到\(y\)，即通过样本\((x,y)\)学习得到,使得其能够准确的预测\(y\)。这类算法叫做判别性学习算法。 本节我们将介绍生成学习型算法。举个例子，对于一个大象，我们可以为大象构造一个关于其特征的模型。对于一条狗，同样可以为狗构造一个关于关于其特征的模型。对于一个新动物，我们可以">
<meta name="twitter:image" content="http://yoursite.com/images/机器学习/监督学习-生成型算法GDA样本.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>机器学习-2.5-监督学习之生成型学习算法 | Hexo</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: undefined
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->






</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">zhengchenyu</a></h1>
        </hgroup>

        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:123@123.com" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注于前端</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">zhengchenyu</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">zhengchenyu</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:123@123.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-机器学习-2-5-监督学习之生成型学习算法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/" class="article-date">
      <time datetime="2017-08-05T08:41:15.000Z" itemprop="datePublished">2017-08-05</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习-2.5-监督学习之生成型学习算法
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <script type="text/javascript" src="/Users/zcy/Desktop/study/git/MathJax-master/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h1 id="生成型学习算法"><a href="#生成型学习算法" class="headerlink" title="生成型学习算法"></a>生成型学习算法</h1><h2 id="1-生成型学习算法简述"><a href="#1-生成型学习算法简述" class="headerlink" title="1 生成型学习算法简述"></a>1 生成型学习算法简述</h2><p>我们之前讲到的算法。譬如逻辑回归，试图从\(x\)直接学习得到一组映射关系到\(y\)，即通过样本\((x,y)\)学习得到,使得其能够准确的预测\(y\)。这类算法叫做判别性学习算法。</p>
<p>本节我们将介绍生成学习型算法。举个例子，对于一个大象，我们可以为大象构造一个关于其特征的模型。对于一条狗，同样可以为狗构造一个关于关于其特征的模型。对于一个新动物，我们可以根据前述构建的模型，判断这个动物是像大象多一点还是像狗多一点，来确定这动物是大象还是狗。</p>
<p>我们可以根据样本得到大象的特征模型\(p(x|y=0)\)和狗的特征模型\(p(x|y=1)\)，同时也可以得到\(p(y)\)。根据贝叶斯公式，有如下：</p>
$$\max (p(y|x)) = \max (\frac{p(x|y)p(y)}{p(x)}) = \max (\frac{p(x|y)p(y)}{p(x|y = 1)p(y = 1) + p(x|y = 0)p(y = 0)})$$

<p>对于我们做预测的时候，可以不考虑分母。</p>
$$\max (p(y|x)) = \max (p(x|y)p(y))$$

<blockquote>
<p>为什么不考虑分母?我们可以将\(p(x|y)p(y)\)简化为\(f(y)\),因此分母就是\(f(1)+f(0)\)。如果我们通过样本对完成了建模，因此分母就是一个常数了，因此没有计算的必要了。</p>
</blockquote>
<h2 id="2-高斯判别分析"><a href="#2-高斯判别分析" class="headerlink" title="2 高斯判别分析"></a>2 高斯判别分析</h2><h3 id="2-1-多维高斯分布介绍"><a href="#2-1-多维高斯分布介绍" class="headerlink" title="2.1 多维高斯分布介绍"></a>2.1 多维高斯分布介绍</h3><p>略，详见cs229-note2.pdf</p>
<h3 id="2-2-高斯判别分析模型"><a href="#2-2-高斯判别分析模型" class="headerlink" title="2.2 高斯判别分析模型"></a>2.2 高斯判别分析模型</h3><p>对于一个分类问题,\(y \in (0,1)\)。假设\(x\)是连续的随机变量，服从高斯分布。具体描述如下：</p>
$$y \sim Bernoulli(\phi)$$$$x|y = 0 \sim N({\mu _0},\Sigma)$$$$x|y = 1 \sim N({\mu _1},\Sigma)$$
$$p(x|y = 0) = \frac{1}{{{(2\pi )}^{\frac{n}{2}}}|\Sigma {|^{\frac{n}{2}}}}\exp ( - \frac{1}{2}{(x - {\mu _0})^T}{\Sigma ^{ - 1}}(x - {\mu _0}))$$
$$p(x|y = 1) = \frac{1}{{{(2\pi )}^{\frac{n}{2}}}|\Sigma {|^{\frac{n}{2}}}}\exp ( - \frac{1}{2}{(x - {\mu _1})^T}{\Sigma ^{ - 1}}(x - {\mu _1}))$$

<h3 id="2-3-公式推导"><a href="#2-3-公式推导" class="headerlink" title="2.3 公式推导"></a>2.3 公式推导</h3><p>我们设置\(\phi  = p(y = 0)\)。根据前面的分析，在给定样本的情况下，我们需要保证下式最大。</p>
$$\prod\limits _{i = 1}^m {p({y^i}|{x^i})}  = \prod\limits _{i = 1}^m {p({x^i}|{y^i})p({y^i})}$$

<p>这里为了简写，我们设置\({z _0} = x - {\mu _0}\) ，\({z _1} = x - {\mu _1}\)。取自然对数后，得到最大释然函数:</p>

$$\ell ({\mu _1},{\mu _1},\Sigma ,\phi ) = \sum\limits _{i = 1}^m {\ln \{ {{[\frac{1}{{{{(2\pi )}^{\frac{n}{2}}}|\Sigma {|^{\frac{n}{2}}}}}\exp ( - \frac{1}{2}z _0^T{\Sigma ^{ - 1}}{z _0})]}^{1\{ {y^i} = 0\} }}{{[\frac{1}{{{{(2\pi )}^{\frac{n}{2}}}|\Sigma {|^{\frac{n}{2}}}}}\exp ( - \frac{1}{2}z _1^T{\Sigma ^{ - 1}}{z _1})]}^{1\{ {y^i} = 1\} }}\} } $$
$$\ell ({\mu _0},{\mu _1},\Sigma ,\phi ) = \sum\limits _{i = 1}^m {\{ 1\{ {y^i} = 0\} [ - \frac{1}{2}z _0^T{\Sigma ^{ - 1}}{z _0} - \frac{n}{2}\ln 2\pi  - \frac{n}{2}\ln |\Sigma | + \ln \phi ] + 1\{ {y^i} = 1\} } [ - \frac{1}{2}z _1^T{\Sigma ^{ - 1}}{z _1} - \frac{n}{2}\ln 2\pi  - \frac{n}{2}\ln |\Sigma | + \ln (1 - \phi )]\}$$

<p>然后我们分别对各个参数求偏导数:</p>

$$\frac{{\partial \ell ({\mu _0},{\mu _1},\sum ,\phi )}}{{\partial \phi }} = \sum\limits _{i = 1}^m {(\frac{{1\{ {y^i} = 1\} }}{\phi } - \frac{{1\{ {y^i} = 0\} }}{{1 - \phi }})}  = \sum\limits _{i = 1}^n {(\frac{{1\{ {y^i} = 1\} }}{\phi } - \frac{{1 - 1\{ {y^i} = 1\} }}{{1 - \phi }})}  = 0$$

<p>所以有:</p>

$$\phi  = \frac{1}{m}\sum\limits _{i = 1}^n {1\{ {y^i} = 1\} }$$

<p>然后对\(\mu _0\)求导：</p>

$${\nabla _{{\mu _0}}}\ell ({\mu _0},{\mu _1},\Sigma ,\phi ) = \sum\limits _{i = 1}^m {{\nabla _{{\mu _0}}}( - \frac{1}{2}{{({x^i} - {\mu _0})}^T}{\Sigma ^{ - 1}}({x^i} - {\mu _0}))1\{ {y^i} = 0\} }$$$${\nabla _{{\mu _0}}}\ell ({\mu _0},{\mu _1},\Sigma ,\phi ) =  - \frac{1}{2}\sum\limits _{i = 1}^m {{\nabla _{{\mu _0}}}( - \mu _0^T{\Sigma ^{ - 1}}{x^i} - {{({x^i})}^T}{\Sigma ^{ - 1}}{\mu _0} + \mu _0^T{\Sigma ^{ - 1}}{\mu _0})1\{ {y^i} = 0\} }$$
<p>我们对上面的式子分头计算。</p>
<blockquote>
<p>\(\Sigma\)为对角阵。由于求偏微分的数为一个常数，因此该值与其迹的相同。另外，这里使用了一些关于迹的公式。具体详见附录。</p>
</blockquote>

$${\nabla _{{\mu _0}}}\mu _0^T{\Sigma ^{ - 1}}x = {\nabla _{{\mu _0}}}tr(\mu _0^T{\Sigma ^{ - 1}}{x^i}) = {[{\nabla _{\mu _0^T}}tr(\mu _0^T{\Sigma ^{ - 1}}{x^i})]^T} = {[{({\Sigma ^{ - 1}}{x^i})^T}]^T} = {\Sigma ^{ - 1}}{x^i}$$
$${\nabla _{{\mu _0}}}{({x^i})^T}{\Sigma ^{ - 1}}{\mu _0} = {\nabla _{{\mu _0}}}tr({({x^i})^T}{\Sigma ^{ - 1}}{\mu _0}) = {\nabla _{{\mu _0}}}{\mu _0}{({x^i})^T}{\Sigma ^{ - 1}} = {({({x^i})^T}{\Sigma ^{ - 1}})^T} = {\Sigma ^{ - 1}}{x^i}$$
$${\nabla _{{\mu _0}}}\mu _0^T{\Sigma ^{ - 1}}{\mu _0} = {[{\nabla _{\mu _0^T}}\mu _0^T{\Sigma ^{ - 1}}{\mu _0}E]^T} = [E\mu _0^T{\Sigma ^{ - 1}} + {E^T}\mu _0^T{({\Sigma ^{ - 1}})^T}] = 2{\Sigma ^{ - 1}}{\mu _0}$$

<p>所以有:</p>

$${\nabla _{{\mu _0}}}\ell ({\mu _0},{\mu _1},\Sigma ,\phi ) =  - \sum\limits _{i = 1}^m {{\nabla _{{\mu _0}}}({\Sigma ^{ - 1}}{\mu _0} - {\Sigma ^{ - 1}}{x^i})1\{ {y^i} = 0\} }  = 0$$
$${\mu _0} = \frac{{\sum\limits _{i = 1}^m {1\{ {y^i} = 0\} {x^i}} }}{{\sum\limits _{i = 1}^m {1\{ {y^i} = 0\} } }}$$

<p>同理有:</p>

$${\mu _1} = \frac{{\sum\limits _{i = 1}^m {1\{ {y^i} = 1\} {x^i}} }}{{\sum\limits _{i = 1}^m {1\{ {y^i} = 1\} } }}$$

<p>然后对\(\Sigma^{-1}\)求偏导数。</p>
$${\nabla _{{\Sigma ^{ - 1}}}}\ell ({\mu _0},{\mu _1},\Sigma ,\phi ) = \sum\limits _{i = 1}^m {{\nabla _{{\Sigma ^{ - 1}}}}[( - \frac{1}{2}z _0^T{\Sigma ^{ - 1}}{z _0} + \frac{1}{2}\ln \frac{1}{{|\Sigma |}})1\{ {y^i} = 0\}  + ( - \frac{1}{2}z _1^T{\Sigma ^{ - 1}}{z _1} + \frac{1}{2}\ln \frac{1}{{|\Sigma |}})1\{ {y^i} = 1\} ]}$$

<p>这里分开计算:</p>

$${\nabla _{\Sigma ^{ - 1}}}(z _0^T{\Sigma ^{ - 1}}{z _0}) = {\nabla _{\sum ^{ - 1}}}tr(z _0^T{\Sigma ^{ - 1}}{z _0}) = {\nabla _{\sum ^{ - 1}}}tr({\Sigma ^{ - 1}}{z _0}z _0^T) = {({z _0}z _0^T)^T} = {z _0}z _0^T$$
$${\nabla _{\Sigma ^{ - 1}}}\ln \frac{1}{|\Sigma |} = {\nabla _{\Sigma ^{ - 1}}}\ln |{\Sigma ^{ - 1}}| = \frac{1}{|{\Sigma ^{ - 1}}|}{\nabla _{\Sigma ^{ - 1}}}{\Sigma ^{ - 1}} = {({({\Sigma ^{ - 1}})^{ - 1}})^T}$$

<p>所以有:</p>

$${\nabla _{{\sum ^{ - 1}}}}\ell ({\mu _0},{\mu _1},\Sigma ,\phi ) = \sum\limits _{i = 1}^m {[( - \frac{1}{2}{z _0}z _0^T + \frac{1}{2}\Sigma )1\{ {y^i} = 0\}  + ( - \frac{1}{2}{z _1}z _1^T + \frac{1}{2}\Sigma )1\{ {y^i} = 1\} ]}  = 0$$
$$\Sigma  = \frac{1}{m}\sum\limits _{i = 1}^m {[({x^i} - {\mu _0}){{({x^i} - {\mu _0})}^T}1\{ {y^i} = 0\}  + ({x^i} - {\mu _1}){{({x^i} - {\mu _1})}^T}1\{ {y^i} = 1\} ]}$$
$$\Sigma  = \frac{1}{m}\sum\limits _{i = 1}^m {[({x^i} - {\mu _{{y^i}}}){{({x^i} - {\mu _{{y^i}}})}^T}]}$$
<h2 id="2-3-高斯型算法实例"><a href="#2-3-高斯型算法实例" class="headerlink" title="2.3 高斯型算法实例"></a>2.3 高斯型算法实例</h2><p>我们分别以 \((1,1)\)和\((2,2)\)为均值生成一组高斯分布。下面图是生成的样本。</p>
<p><img src="/images/机器学习/监督学习-生成型算法GDA样本.png" width="50%" height="50%" text-align="center/"></p>
<p>前提假设是我们知道两组分类是符合高斯分布的，切假定协方差相同。但我们不知道两组数据的均值和协方差。根据前面的公式有如下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">from</span> matplotlib.lines <span class="keyword">import</span> Line2D</div><div class="line"></div><div class="line"><span class="comment">## this is a program about GDA</span></div><div class="line"></div><div class="line"><span class="keyword">global</span> MAKE_DATA</div><div class="line"><span class="keyword">global</span> SHOW_PIC</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_data</span><span class="params">(x)</span>:</span></div><div class="line">  <span class="keyword">if</span> MAKE_DATA == <span class="keyword">True</span>:</div><div class="line">    mean_1 = [<span class="number">1</span>,<span class="number">1</span>]</div><div class="line">    mean_2 = [<span class="number">2</span>,<span class="number">2</span>]</div><div class="line">    cov = [[<span class="number">0.1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0.1</span>]]</div><div class="line">    arr1 = np.random.multivariate_normal(mean_1, cov, <span class="number">100</span>)</div><div class="line">    arr2 = np.random.multivariate_normal(mean_2, cov, <span class="number">50</span>)</div><div class="line">    print(arr1)</div><div class="line">    print(arr2)</div><div class="line">    x.append(arr1)</div><div class="line">    x.append(arr2)</div><div class="line">  <span class="keyword">if</span> MAKE_DATA == <span class="keyword">False</span>:</div><div class="line">    arr1 = np.array([[ <span class="number">0.88235916</span> , <span class="number">1.01511634</span>],[ <span class="number">0.75243817</span> , <span class="number">0.76520033</span>],[ <span class="number">0.95710848</span> , <span class="number">1.41894337</span>],[ <span class="number">1.48682891</span> , <span class="number">0.78885043</span>],[ <span class="number">1.24047011</span> , <span class="number">0.71984948</span>],[ <span class="number">0.67611276</span> , <span class="number">1.07909452</span>],[ <span class="number">1.03243669</span> , <span class="number">1.08929695</span>],[ <span class="number">1.0296548</span>  , <span class="number">1.25023769</span>],[ <span class="number">1.54134008</span> , <span class="number">0.39564824</span>],[ <span class="number">0.34645057</span> , <span class="number">1.61499636</span>],[ <span class="number">0.77206174</span> , <span class="number">1.23613698</span>],[ <span class="number">0.91446988</span> , <span class="number">1.38537765</span>],[ <span class="number">0.99982962</span> , <span class="number">1.34448471</span>],[ <span class="number">0.78745962</span> , <span class="number">0.9046565</span> ],[ <span class="number">0.74946602</span> , <span class="number">1.07424473</span>],[ <span class="number">1.09294839</span> , <span class="number">1.14711993</span>],[ <span class="number">0.39266844</span> , <span class="number">0.78788004</span>],[ <span class="number">0.83112357</span> , <span class="number">1.2762774</span> ],[ <span class="number">1.05056188</span> , <span class="number">1.13351562</span>],[ <span class="number">1.62101523</span> , <span class="number">1.15035562</span>],[ <span class="number">0.70377517</span> , <span class="number">1.1136416</span> ],[ <span class="number">1.03715472</span> , <span class="number">0.47905693</span>],[ <span class="number">0.94598381</span> , <span class="number">0.8874837</span> ],[ <span class="number">0.94447128</span> , <span class="number">2.02796925</span>],[ <span class="number">0.72442242</span> , <span class="number">1.09835206</span>],[ <span class="number">0.69046731</span> , <span class="number">1.46232182</span>],[ <span class="number">1.20744606</span> , <span class="number">1.10280041</span>],[ <span class="number">0.70665746</span> , <span class="number">0.82139503</span>],[ <span class="number">1.08803887</span> , <span class="number">1.4450361</span> ],[ <span class="number">0.88530961</span> , <span class="number">0.75727475</span>],[ <span class="number">0.98418545</span> , <span class="number">0.80248161</span>],[ <span class="number">0.74970386</span> , <span class="number">1.13205709</span>],[ <span class="number">0.72586454</span> , <span class="number">1.06058385</span>],[ <span class="number">0.9071812</span>  , <span class="number">1.09975063</span>],[ <span class="number">0.75182835</span> , <span class="number">0.93570147</span>],[ <span class="number">0.80052289</span> , <span class="number">1.08168507</span>],[ <span class="number">0.40180652</span> , <span class="number">0.9526211</span> ],[ <span class="number">0.62312617</span> , <span class="number">0.84385058</span>],[ <span class="number">0.68212516</span> , <span class="number">1.25912717</span>],[ <span class="number">1.19773245</span> , <span class="number">0.16399654</span>],[ <span class="number">0.96093132</span> , <span class="number">0.43932091</span>],[ <span class="number">1.25471657</span> , <span class="number">0.92371829</span>],[ <span class="number">1.12330272</span> , <span class="number">1.26968747</span>],[ <span class="number">1.30361985</span> , <span class="number">0.99862123</span>],[ <span class="number">1.23477665</span> , <span class="number">1.1742804</span> ],[ <span class="number">0.28471876</span> , <span class="number">0.5806044</span> ],[ <span class="number">1.89355099</span> , <span class="number">1.19928671</span>],[ <span class="number">1.09081369</span> , <span class="number">1.28467312</span>],[ <span class="number">1.40488635</span> , <span class="number">0.90034427</span>],[ <span class="number">1.11672364</span> , <span class="number">1.49070515</span>],[ <span class="number">1.35385212</span> , <span class="number">1.35767891</span>],[ <span class="number">0.92746374</span> , <span class="number">1.79096697</span>],[ <span class="number">1.89142562</span> , <span class="number">0.98228303</span>],[ <span class="number">1.0555218</span>  , <span class="number">0.86070833</span>],[ <span class="number">0.69001255</span> , <span class="number">1.12874741</span>],[ <span class="number">0.98137315</span> , <span class="number">1.3398852</span> ],[ <span class="number">1.02525371</span> , <span class="number">0.77572865</span>],[ <span class="number">1.1354295</span>  , <span class="number">1.07098552</span>],[ <span class="number">1.50829164</span> , <span class="number">1.43065998</span>],[ <span class="number">1.09928764</span> , <span class="number">1.55540292</span>],[ <span class="number">0.64695084</span> , <span class="number">0.79920395</span>],[ <span class="number">0.82059034</span> , <span class="number">0.97533491</span>],[ <span class="number">0.56345455</span> , <span class="number">1.08168272</span>],[ <span class="number">1.06673215</span> , <span class="number">1.19448556</span>],[ <span class="number">0.96512548</span> , <span class="number">1.5268577</span> ],[ <span class="number">0.96914451</span> , <span class="number">1.00902985</span>],[ <span class="number">0.72879413</span> , <span class="number">0.92476415</span>],[ <span class="number">1.0931483</span>  , <span class="number">1.13572242</span>],[ <span class="number">1.34765121</span> , <span class="number">0.83841006</span>],[ <span class="number">1.57813788</span> , <span class="number">0.65915892</span>],[ <span class="number">0.59032608</span> , <span class="number">0.82747946</span>],[ <span class="number">0.83838504</span> , <span class="number">0.67588473</span>],[ <span class="number">1.35101322</span> , <span class="number">1.21027851</span>],[ <span class="number">0.71762153</span> , <span class="number">0.41839038</span>],[ <span class="number">0.61295604</span> , <span class="number">0.66555018</span>],[ <span class="number">0.64379346</span> , <span class="number">0.92925228</span>],[ <span class="number">1.1194968</span>  , <span class="number">0.65876736</span>],[ <span class="number">0.39495437</span> , <span class="number">0.67246734</span>],[ <span class="number">1.05223282</span> , <span class="number">0.17889116</span>],[ <span class="number">0.97810984</span> , <span class="number">1.12794664</span>],[ <span class="number">0.98392719</span> , <span class="number">0.73590255</span>],[ <span class="number">1.25587405</span> , <span class="number">1.21853038</span>],[ <span class="number">1.01150226</span> , <span class="number">1.01835571</span>],[ <span class="number">1.02251614</span> , <span class="number">0.72704228</span>],[ <span class="number">1.00261519</span> , <span class="number">0.95347185</span>],[ <span class="number">0.96362523</span> , <span class="number">0.8607009</span> ],[ <span class="number">0.88034659</span> , <span class="number">1.2307104</span> ],[ <span class="number">0.75907236</span> , <span class="number">0.92799796</span>],[ <span class="number">0.54898709</span> , <span class="number">1.69882285</span>],[ <span class="number">0.55032649</span> , <span class="number">0.98831566</span>],[ <span class="number">1.33360789</span> , <span class="number">1.19793298</span>],[ <span class="number">0.83231239</span> , <span class="number">0.8946538</span> ],[ <span class="number">1.05173094</span> , <span class="number">1.26324289</span>],[ <span class="number">0.81482231</span> , <span class="number">0.56198584</span>],[ <span class="number">1.03854797</span> , <span class="number">1.0553811</span> ],[ <span class="number">1.32669227</span> , <span class="number">1.61115811</span>],[ <span class="number">1.13322152</span> , <span class="number">1.68151695</span>],[ <span class="number">0.39754618</span> , <span class="number">1.19392967</span>],[ <span class="number">0.61344185</span> , <span class="number">1.05281434</span>],[ <span class="number">1.18415366</span> , <span class="number">0.864884</span>  ]])</div><div class="line">    arr2 = np.array([[ <span class="number">2.15366548</span> , <span class="number">1.88035458</span>],[ <span class="number">2.36978774</span> , <span class="number">1.76550283</span>],[ <span class="number">2.46261387</span> , <span class="number">2.10568262</span>],[ <span class="number">1.90475526</span> , <span class="number">1.95242885</span>],[ <span class="number">1.77712677</span> , <span class="number">1.96004856</span>],[ <span class="number">1.5995514</span>  , <span class="number">2.1323943</span> ],[ <span class="number">1.52727223</span> , <span class="number">1.50295551</span>],[ <span class="number">1.80330407</span> , <span class="number">1.57942301</span>],[ <span class="number">1.86487049</span> , <span class="number">1.87234414</span>],[ <span class="number">1.9586354</span>  , <span class="number">1.96279729</span>],[ <span class="number">2.59668134</span> , <span class="number">2.414423</span>  ],[ <span class="number">2.818419</span>   , <span class="number">1.76280366</span>],[ <span class="number">2.01511628</span> , <span class="number">2.10858546</span>],[ <span class="number">2.15907962</span> , <span class="number">1.81593012</span>],[ <span class="number">1.63966834</span> , <span class="number">2.2209023</span> ],[ <span class="number">2.47220599</span> , <span class="number">1.70482956</span>],[ <span class="number">2.08760748</span> , <span class="number">2.51601971</span>],[ <span class="number">1.50547722</span> , <span class="number">1.8487145</span> ],[ <span class="number">1.68125583</span> , <span class="number">2.64968501</span>],[ <span class="number">2.01924282</span> , <span class="number">2.0953572</span> ],[ <span class="number">2.22563534</span> , <span class="number">2.18266325</span>],[ <span class="number">2.2684291</span>  , <span class="number">2.23581599</span>],[ <span class="number">2.13787557</span> , <span class="number">1.9999382</span> ],[ <span class="number">1.02638695</span> , <span class="number">1.68134967</span>],[ <span class="number">2.35614619</span> , <span class="number">1.32072125</span>],[ <span class="number">2.20054871</span> , <span class="number">1.47401445</span>],[ <span class="number">1.99454827</span> , <span class="number">1.71658741</span>],[ <span class="number">1.83269065</span> , <span class="number">2.47662909</span>],[ <span class="number">2.40097251</span> , <span class="number">2.21823862</span>],[ <span class="number">2.54404652</span> , <span class="number">1.85742018</span>],[ <span class="number">1.84150027</span> , <span class="number">2.06350351</span>],[ <span class="number">1.69490855</span> , <span class="number">1.70169334</span>],[ <span class="number">1.44745704</span> , <span class="number">1.88295233</span>],[ <span class="number">2.24376639</span> , <span class="number">1.67530495</span>],[ <span class="number">1.42911921</span> , <span class="number">1.81854548</span>],[ <span class="number">1.33789289</span> , <span class="number">2.27686128</span>],[ <span class="number">2.43509821</span> , <span class="number">1.95032131</span>],[ <span class="number">1.9512447</span>  , <span class="number">1.4595415</span> ],[ <span class="number">2.13041192</span> , <span class="number">1.79372755</span>],[ <span class="number">2.2753866</span>  , <span class="number">2.23781951</span>],[ <span class="number">2.26753401</span> , <span class="number">1.78149305</span>],[ <span class="number">2.06505449</span> , <span class="number">2.01939606</span>],[ <span class="number">2.44426826</span> , <span class="number">2.1437101</span> ],[ <span class="number">2.16607141</span> , <span class="number">2.31077167</span>],[ <span class="number">1.96097237</span> , <span class="number">2.49100193</span>],[ <span class="number">1.37255424</span> , <span class="number">1.60735016</span>],[ <span class="number">1.63947758</span> , <span class="number">2.17852314</span>],[ <span class="number">2.13722666</span> , <span class="number">2.00559707</span>],[ <span class="number">1.222696</span>   , <span class="number">1.67075059</span>],[ <span class="number">2.56982685</span> , <span class="number">2.51218813</span>]])</div><div class="line">    x.append(arr1)</div><div class="line">    x.append(arr2)</div><div class="line">  <span class="keyword">if</span> SHOW_PIC == <span class="number">1</span>:</div><div class="line">    figure, ax = plt.subplots()</div><div class="line">    ax.set_xlim(left=<span class="number">-1</span>, right=<span class="number">4</span>)</div><div class="line">    ax.set_ylim(bottom=<span class="number">-1</span>, top=<span class="number">4</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr1)):</div><div class="line">      plt.plot(arr1[i][<span class="number">0</span>], arr1[i][<span class="number">1</span>], <span class="string">'b--'</span>, marker=<span class="string">'+'</span>, color=<span class="string">'g'</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr2)):</div><div class="line">      plt.plot(arr2[i][<span class="number">0</span>], arr2[i][<span class="number">1</span>], <span class="string">'b--'</span>, marker=<span class="string">'o'</span>, color=<span class="string">'b'</span>)</div><div class="line">    plt.xlabel(<span class="string">"x1"</span>)</div><div class="line">    plt.ylabel(<span class="string">"x2"</span>)</div><div class="line">    plt.plot()</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcPhi</span><span class="params">(x)</span>:</span></div><div class="line">  <span class="keyword">return</span> len(x[<span class="number">1</span>])/(len(x[<span class="number">0</span>])+len(x[<span class="number">1</span>]))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcMu</span><span class="params">(x,i)</span>:</span></div><div class="line">  <span class="keyword">return</span> x[i].mean(axis=<span class="number">0</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcSigma</span><span class="params">(x,mu_0,mu_1)</span>:</span></div><div class="line">  sum=np.array([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>]])</div><div class="line">  x0=x[<span class="number">0</span>]</div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x0)):</div><div class="line">    z0=np.array([x0[i]-mu_0])</div><div class="line">    z0T = np.array([x0[i]-mu_0]).transpose()</div><div class="line">    sum = sum + np.dot(z0T, z0)</div><div class="line">    print(np.dot(z0T, z0))</div><div class="line">  x1=x[<span class="number">1</span>]</div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x1)):</div><div class="line">    z1=np.array([x1[i]-mu_1])</div><div class="line">    z1T = np.array([x1[i]-mu_1]).transpose()</div><div class="line">    sum = sum + np.dot(z1T, z1)</div><div class="line">    print(np.dot(z1T, z1))</div><div class="line">  <span class="keyword">return</span> sum/(len(x0)+len(x1))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(x,mu_0,mu_1,sigma,phi)</span>:</span></div><div class="line">  var0 = multivariate_normal(mean=mu_0.tolist(), cov=sigma.tolist())</div><div class="line">  var1 = multivariate_normal(mean=mu_1.tolist(), cov=sigma.tolist())</div><div class="line">  <span class="comment"># p(y=1|x) = p(x|y=1)/p(y=1) / p(x) = p(x|y=1)p(y=1) / (p(x|y=1)p(y=1)+p(x|y=0)p(y=0))</span></div><div class="line">  <span class="keyword">return</span> var1.pdf(x)*phi/(var1.pdf(x)*phi+var0.pdf(x)*(<span class="number">1</span>-phi)) &gt; <span class="number">0.5</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testClassify</span><span class="params">(mu_0,mu_1,sigma,phi)</span>:</span></div><div class="line">  <span class="keyword">if</span> SHOW_PIC != <span class="number">2</span>:</div><div class="line">    <span class="keyword">return</span></div><div class="line">  figure, ax = plt.subplots()</div><div class="line">  ax.set_xlim(left=<span class="number">-1</span>, right=<span class="number">4</span>)</div><div class="line">  ax.set_ylim(bottom=<span class="number">-1</span>, top=<span class="number">4</span>)</div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</div><div class="line">    x1 = random.randint(<span class="number">0</span>,<span class="number">3000</span>)/<span class="number">1000</span></div><div class="line">    x2 = random.randint(<span class="number">0</span>,<span class="number">3000</span>)/<span class="number">1000</span></div><div class="line">    <span class="keyword">if</span>( classify([x1,x2],mu_0,mu_1,sigma,phi)) == <span class="keyword">True</span>:</div><div class="line">      plt.plot(x1, x2, <span class="string">'b--'</span>, marker=<span class="string">'+'</span>, color=<span class="string">'g'</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      plt.plot(x1, x2, <span class="string">'b--'</span>, marker=<span class="string">'o'</span>, color=<span class="string">'b'</span>)</div><div class="line">  <span class="comment"># draw y = -x+3</span></div><div class="line">  (line1_xs, line1_ys) = [(<span class="number">0</span>, <span class="number">3</span>), (<span class="number">3</span>, <span class="number">0</span>)]</div><div class="line">  ax.add_line(Line2D(line1_xs, line1_ys, linewidth=<span class="number">1</span>, color=<span class="string">'blue'</span>))</div><div class="line">  plt.xlabel(<span class="string">"x1"</span>)</div><div class="line">  plt.ylabel(<span class="string">"x2"</span>)</div><div class="line">  plt.plot()</div><div class="line">  plt.show()</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  <span class="comment"># 0 debug option</span></div><div class="line">  MAKE_DATA = <span class="keyword">False</span></div><div class="line">  SHOW_PIC = <span class="number">1</span>        <span class="comment"># 0 - do not show   1 - show sample data    2 - show test data</span></div><div class="line"></div><div class="line">  <span class="comment"># 1 make the sample</span></div><div class="line">  <span class="comment"># the format of x is [ndarray0,ndarray1] , ndarray1 is the set of the first class, we set y=0.</span></div><div class="line">  <span class="comment"># ndarray1 is the set of the second class, we set y=1</span></div><div class="line">  x = []</div><div class="line">  make_data(x)</div><div class="line"></div><div class="line">  <span class="keyword">if</span> MAKE_DATA == <span class="keyword">True</span>:</div><div class="line">    exit(<span class="number">0</span>)</div><div class="line"></div><div class="line">  <span class="comment"># 2 learn from the sample</span></div><div class="line">  print(<span class="string">"hello"</span>)</div><div class="line">  phi = calcPhi(x)                <span class="comment"># phi  = p(y=1)  means close (2,2)</span></div><div class="line">  mu_0 = calcMu(x,<span class="number">0</span>)</div><div class="line">  mu_1 = calcMu(x,<span class="number">1</span>)</div><div class="line">  sigma = calcSigma(x,mu_0,mu_1)</div><div class="line">  print(phi,<span class="string">", "</span>,mu_0,<span class="string">", "</span>,mu_1)</div><div class="line">  print(sigma.tolist())</div><div class="line"></div><div class="line">  print(<span class="string">"---------"</span>)</div><div class="line">  <span class="comment"># 3 test classify</span></div><div class="line">  testClassify(mu_0,mu_1,sigma,phi)</div></pre></td></tr></table></figure>
<p>对于两个协方差相同的样本，我们知道两组数据有相同的概率分布曲线，具体都应该是一个个同心圆。因此，我们可以确定一条垂直于两点连线的曲线是对该样本的理论上正确的分割。因此，我们得到如下结果，并与理论分割的曲线，即\(y=-x+3\)比较，发现对我们随机产生的样本分类效果非常好。</p>
<p><img src="/images/机器学习/监督学习-生成型算法GDA结果.png" width="50%" height="50%" text-align="center/"></p>
<h2 id="附录-A-相关公式"><a href="#附录-A-相关公式" class="headerlink" title="附录 A 相关公式"></a>附录 A 相关公式</h2><p>Hessian矩阵定义:</p>
$${\nabla _A}f(A) = \left( {\begin{array}{*{20}{c}}  {\frac{{\partial f}}{{\partial {A _{11}}}}}& \ldots &{\frac{{\partial f}}{{\partial {A _{1n}}}}} \\\    \vdots & \ddots & \vdots  \\\   {\frac{{\partial f}}{{\partial {A _{n1}}}}}& \cdots &{\frac{{\partial f}}{{\partial {A _{nn}}}}} \end{array}} \right)$$

<p>矩阵的迹的定义:</p>

$$trA = \sum\limits _{i = 1}^n {{A _{ii}}}$$

<p>关于矩阵迹的公式:</p>

$$tr(a) = a$$
$$tr(aA) = atr(A)$$
$$tr(aA) = atr(A)$$
$$tr(ABC) = tr(CAB) + tr(BCA)$$
$$trA = tr{A^T}$$
$$tr(A + B) = trA + trB$$
$${\nabla _A}tr(AB) = {B^T}$$
$${\nabla _{A^T}}f(A) = {({\nabla _A}f(A))^T}$$
$${\nabla _{A^T}}trAB{A^T}C = CAB + {C^T}A{B^T}$$
$${\nabla _{A^T}}trAB{A^T}C = CAB + {C^T}A{B^T}$$

<blockquote>
<p>对矩阵做展开能证明上述大部分公式，这里暂时略。</p>
</blockquote>
<h2 id="附录B"><a href="#附录B" class="headerlink" title="附录B"></a>附录B</h2><p>手写公式和word版博客地址:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">https://github.com/zhengchenyu/MyBlog/tree/master/doc/mlearning/生成型学习算法</div></pre></td></tr></table></figure>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/">机器学习-2.5-监督学习之生成型学习算法</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">zhengchenyu</a></p>
        <p><span>发布时间:</span>2017-08-05, 16:41:15</p>
        <p><span>最后更新:</span>2017-08-05, 20:51:24</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/" title="机器学习-2.5-监督学习之生成型学习算法">http://yoursite.com/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/</a>
            <span class="copy-path" data-clipboard-text="原文: http://yoursite.com/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/　　作者: zhengchenyu" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2017/08/05/机器学习-2-6-监督学习之朴素贝叶斯算法/">
                    机器学习-2.6-监督学习之朴素贝叶斯算法
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2017/07/24/机器学习-2-4-监督学习之softmax/">
                    机器学习-2.4-监督学习之softmax
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#生成型学习算法"><span class="toc-number">1.</span> <span class="toc-text">生成型学习算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-生成型学习算法简述"><span class="toc-number">1.1.</span> <span class="toc-text">1 生成型学习算法简述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-高斯判别分析"><span class="toc-number">1.2.</span> <span class="toc-text">2 高斯判别分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-多维高斯分布介绍"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 多维高斯分布介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-高斯判别分析模型"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 高斯判别分析模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-公式推导"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 公式推导</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-高斯型算法实例"><span class="toc-number">1.3.</span> <span class="toc-text">2.3 高斯型算法实例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#附录-A-相关公式"><span class="toc-number">1.4.</span> <span class="toc-text">附录 A 相关公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#附录B"><span class="toc-number">1.5.</span> <span class="toc-text">附录B</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"机器学习-2.5-监督学习之生成型学习算法　| Hexo　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2017/08/05/机器学习-2-6-监督学习之朴素贝叶斯算法/" title="上一篇: 机器学习-2.6-监督学习之朴素贝叶斯算法">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2017/07/24/机器学习-2-4-监督学习之softmax/" title="下一篇: 机器学习-2.4-监督学习之softmax">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/10/22/机器学习-3-2-非监督学习之主成分分析/">机器学习-3.2-非监督学习之主成分分析.md</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/15/机器学习-2-8-监督学习之k近邻算法/">机器学习-2.8-监督学习之k近邻算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/24/机器学习-3-1-非监督学习之聚类/">机器学习-3.1-非监督学习之聚类.md</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/08/机器学习-2-7-监督学习之支持向量机/">机器学习-2.7-监督学习之支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/05/机器学习-2-6-监督学习之朴素贝叶斯算法/">机器学习-2.6-监督学习之朴素贝叶斯算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/05/机器学习-2-5-监督学习之生成型学习算法/">机器学习-2.5-监督学习之生成型学习算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/24/机器学习-2-4-监督学习之softmax/">机器学习-2.4-监督学习之softmax</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/16/机器学习-2.3-监督学习之通用线性模型/">机器学习-2.3-监督学习之通用线性模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/13/机器学习-2.2-监督学习之分类/">机器学习 2.2 监督学习之逻辑回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/10/机器学习-2.1-监督学习之线性回归/">机器学习 2.1 监督学习之线性回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/10/机器学习-1-绪论/">机器学习 1 绪论</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/06/MyFirstBlog/">MyFirstBlog</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016-2017 zhengchenyu
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>